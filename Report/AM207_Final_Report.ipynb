{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Texas hold 'em Poker Player AI Design\n",
    "#### AM207 Advanced Scientific Computing: Stochastic Optimization Methods\n",
    "#### By Yung-Jen Cheng, Peiheng Hu, Sail Wu, Xide Xia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poker, Texas hold 'em, is a game of imperfect information, making it impossible for \n",
    "anyone to conclude the final outcome of the hand. Admittedly, we can derive nearly \n",
    "deterministic probability of a given hand from millions of simulation results. However, \n",
    "the way how people react and the psychological components involved in betting make \n",
    "poker one of the most popular card games in the world. This project aims to implement \n",
    "a system which allows the designed computer program to model the style of the player, \n",
    "obtain observations of the style of that player and update the style of the player to play \n",
    "in the game of heads-up unlimited Texas hold 'em."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project we have designed a Heads-up AI Texas hold 'em poker player by using both statisitcally deterministic model and Bayesian analysis on opponent past betting behaviors.In the **Approach** section, we outlined our strategy to design such a complicated system. We explained our methods to create a rational poker AI in greater detail in the **Deterministic Approach**, and Hidden Makov Model and Bayesian MCMC in **Human Behavior Adjustment Approach** section. Since the deliverable is a software, there is not much results analysis involved in this project. We put our source code links in the end. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following flow chart illustrate our approach to design an AI Texas hold 'em poker player:\n",
    "\n",
    "![](approach.png)\n",
    "\n",
    "The top half of the flow charts reflects the deterministic approach, which allows AI to use its excessive computing power to calculate the winning probability and make the statistically optimal betting decisions. Detailed processes are explained in the winning probability calculation section. \n",
    "\n",
    "Besides designing a completely rational AI player, we adopted the knowledge we learned from this courses to analyze the opponent player's past betting record and modified the determinisitc approach in the hope of increasing AI's expected returns. Specifically, we used Hidden Markov Model, HMM, to estimate opponent's hole cards strengths and Bayesian modeling with MCMC to predict opponent's bluff tendency in each of his actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Poker Simulator Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To provide interative experience between user and computer with the capability for the computer to automatically keep track of user's previous behavior and then apply stochastic methods on user behavior, a poker simulator that contains objects such as game and players are created.\n",
    "\n",
    "In object Game, it stores the two players playing the game and keep track of the game progress from randomly shuffling and distributing cards to terminating the game and determineing the winner.\n",
    "\n",
    "In object Player, it contains all the information that player can gain access to, such as what card he has in hand, how much money he has in hand, and also how much money he contributed to the current pot size. Beside these attributes, Player can be either a computer or a user. In this way, the simulator provides the functionality to have two computer players play against each other, two human play with each other, and more importantly, one user and one computer play against each other with the computer capable of learning the user's behavior and making smarter actions.\n",
    "\n",
    "In the game process, everytime of when the user makes an action, we will store a tuple that contains the information of that action in playrs betHistory attribute. The tuple is created with three values, 1. action type, 2. calculated winning probability given the current stage cards in hand and on the table, and 3. betting percentage, which is the betting amount divided by the current total pot size. In this way, the simulator can record every action of the user and pass these past information to the stochastic models for analysis to figure out how good the cards are in user's hand and also how tendency that the user will bluff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Winning Probability Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The winning probability is the probability to win this game, given your hole cards and the known board cards revealed on the table. In the river stage, when all five bard cards are known, we compute this probability by permuting all possible opponent's hole cards and count winning times over total $\\frac{45\\times 44}{2}=990$ combinations. \n",
    "\n",
    "In the turn stage, the method is similar but we need to permute one extra card since only four board cards are known. The computation expenses for the winning probability estimation at the turn stage is less than 1 second. The following figure illustrate the process:\n",
    "\n",
    "![](winning_prob.png)\n",
    "\n",
    "In the flop stage, the number of permutations grows to $\\frac{47\\times46}{2}\\times \\frac{45\\times44}{2} = 1070190$, which is too large to compute on the fly (computation requires more than 40 seconds to compute). Thus, we only sample one tenth of opponent’s hole cards to approximate it.\n",
    "\n",
    "In the preflop stage, we used following tables from the poker statisitcs website, http://seoblackhat.com/texas-hold-em-poker-statistics/ to compute AI's winning probability.\n",
    "\n",
    "![](preflop_win.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Rational Play Flow Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the probability of winning computed from permuting all the combinations, a fixed/deterministic strategy can be deduced.\n",
    "\n",
    "Scenario 1 winning probability > 0.5:  Better off to raise more money. The bet amount is calculated based on the winning probability.\n",
    "\n",
    "Scenario 2 winning probability < 0.5:  Denote winning probability as P, current money in pot is potSize. We want to solve the optimal value to raise, which is x.\n",
    "\n",
    "![\"\"](action.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Behavior Adjustment Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a famous quote about playing Poker, \"A player who never bluffs will never win a big pot\". Inspired by that, many players tend to bluff frequently in the Poker table. In order to make our AI player act like a human, we implemented the Bayesian MCMC method to estimate the opponent's bluff tendency at each action and Hidden Markov Model method to estimate the opponent's hole hand strength. As such, AI's rational betting strategies could be adjusted according to its knowledge of opponent's past behaniors to make higher expected returns from the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Hidden Markov Model Hand Strength Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the following charts to model the strength of opponent's hole hand, based on the revealed information we got from the historical records. Since there are more than 2 million combinations of cards in the poker game, we discretized the states based on each opponent's hand winning probability, and classified them into {Weak,Medium,Strong}: \"Weak\" means hand winning probability is less than 33%, \"Medium\" 33% to 66%, and \"Strong\" larger than 66%. \n",
    "\n",
    "![](hmm_1.png)\n",
    "\n",
    "The transition probability is simplified as in the following chart, which illustrate how likely the hidden state transits among each other in the game.\n",
    "\n",
    "![](hmm_2.png)\n",
    "\n",
    "The observed states in HMM model will be represented by the pairs of action and betting size relative to the pot size. Thus, Observed State, O:{(Call, L), (Call,M), (Call, H), (Raise,L), (Raise,M), (Raise,H)}. Similar to the hole hand strength, we discretized the betting size into low (L), medium (M) and high (H) 3 different classes as well. The emission probability table below is used to calculate the emssion probability for each hidden state and observed state. Through out the game, we used historical records to update the table and compute the probability sequentially.\n",
    "\n",
    "![](hmm_3.png)\n",
    "\n",
    "We used Vit0rbi Algorithm to estimate the player’s most likely hand strength in the current stage. After estimating the player’s hidden hand strength, we adjusted the winning probability accordingly. Please refer to **Strength_HMM.py** for the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Bluff Tendency  Bayesian MCMC Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We model a player’s bluff status with probability with probability $f(\\theta_{1}+\\theta_{2}t)$\n",
    "conditionally on $\\Theta = (\\theta_1, \\theta_2)$. We used $f(z) = 1/(1 + \\exp(-z))$ to denote a player’s likelihood to bluff in each action. $t$ is the player’s betting size relative to pot size. Due to limited prior information for each player, we chose a very flat prior: $\\theta_1,\\theta_2\\sim\\mathcal{N}(0,10^2)$.\n",
    "\n",
    "Thus, Prior can be expressed as: \n",
    "\n",
    "$P(\\theta_1,\\theta_2)=P(\\theta_1)\\times P(\\theta_2)\n",
    "=\\frac{1}{\\sqrt{2\\pi}\\sigma_1\\sqrt{2\\pi}\\sigma_2}\\exp{(-\\frac{\\theta_1^2 }{2\\sigma_1^2}-\\frac{\\theta_2^2 }{2\\sigma_2^2})}\n",
    "=\\frac{1}{2\\pi\\sigma_1\\sigma_2}\\exp{(-\\frac{\\theta_1^2 }{2\\sigma_1^2}-\\frac{\\theta_2^2 }{2\\sigma_2^2})} $\n",
    "Where $\\sigma_1=\\sigma_2=10$\n",
    "\n",
    "We Expressed the likelihood for each action as:\n",
    "\n",
    "$Likelihood_i= \\frac{1}{1+\\exp(-\\theta_1-\\theta_2t_i)}^{y_i}\\times\\frac{\\exp(-\\theta_1-\\theta_2t_i)}{1+\\exp(-\\theta_1-\\theta_2t_i)}^{1-y_i}$\n",
    "\n",
    "Where $y_i \\in \\{0,1\\}$ indicates if the player is bluffing at each action based on if his current winning probability greater than $0.5$. The posterior likelihood can be expressed as :\n",
    "\n",
    "$$P(\\Theta|D) \\propto P(D|\\Theta) \\times P(\\Theta) $$\n",
    "\n",
    "$$P(\\Theta|D)\\propto \\prod_{i=1}^N (\\frac{1}{1+\\exp(-\\theta_1-\\theta_2t_i)}^{y_i}\\times\\frac{\\exp(-\\theta_1-\\theta_2t_i)}{1+\\exp(-\\theta_1-\\theta_2t_i)}^{1-y_i})\\times \\exp{(-\\frac{\\theta_1^2 }{2\\sigma_1^2}-\\frac{\\theta_2^2 }{2\\sigma_2^2})} $$\n",
    "\n",
    "We then used MCMC rejection sampling to estimate the player’s bluff probability, and incorporated that to adjust our winning probability in the overall betting strategies. Please refer to **Bluff_Bayesian_new.py** for the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Integrating Human Beharvior to Deterministic Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following chart shows the adjument AI player made to calculate the winning probability after using HMM adjustment:\n",
    "![](integration.png)\n",
    "\n",
    "Deterministic calculation shows the winning probability is $\\pi^0$, which equals to the shaded area to the left of $\\pi^0$. The adjustment of winning probability calculated based on one of the three states below. \n",
    "\n",
    "We also believe that if the opponent has a higher probability to bluff, we will be less certain about the results from HMM estimation and rely more on the uniform distribution. Thus, the adjusted winning probability will be $\\pi_{adj}=w\\pi^2+(1-w)\\pi_{state}$ \n",
    "Where $w$ is the opponent's probability to make bluff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "• Our project successfully created an AI poker player that can determine the optimal betting strategies that based on both statistics and human behaviors to maximize its profits.\n",
    "\n",
    "• We obtained the statistically optimal betting decision based on calculating the winning percentage for each given hand after permutating all the possible scenarios of the opponent hands.\n",
    "\n",
    "• The human behaviors are captured by the historical records of the players and we used HMM to estimate player’s hand strength and Bayesian MCMC to deduce the whether the player is bluffing at each action.\n",
    "\n",
    "• We have conducted thousands of runs to be tested on both AI poker players for debugging and parameter tunings.\n",
    "\n",
    "• Our sources code could be found on https://github.com/quezacot/AM207Final\n",
    "\n",
    "• Our website is: XXXXXXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Preflop hand strength: http://seoblackhat.com/texas-hold-em-poker-statistics/ \n",
    "2. Poker betting strategies: http://www.pokerlistings.com/strategy/sizing-your-bets-properly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
